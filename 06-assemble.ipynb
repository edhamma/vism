{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7e158a-94e2-4685-990f-314114b3ad34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "II\n",
      "III\n",
      "IV\n",
      "V\n",
      "VI\n",
      "VII\n",
      "VIII\n",
      "IX\n",
      "X\n",
      "XI\n",
      "XII\n",
      "XIII\n",
      "XIV\n",
      "XV\n",
      "XVI\n",
      "XVII\n",
      "XVIII\n",
      "XIX\n",
      "XX\n",
      "XXI\n",
      "XXII\n",
      "XXIII\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34025"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import itertools\n",
    "\n",
    "book=etree.parse('src/book.6.xml',etree.XMLParser(remove_blank_text=True)).getroot() \n",
    "flatBook=list(book.iter())\n",
    "# hand-tuned toc, do not overwrite\n",
    "toc=etree.parse('src/toc.xml',etree.XMLParser()).getroot() \n",
    "\n",
    "def _one_only(pp):\n",
    "    assert(len(pp)==1)\n",
    "    return pp[0]\n",
    "\n",
    "for toc_chap in toc:\n",
    "    chap_num=toc_chap.attrib['num']\n",
    "    print(chap_num)\n",
    "    chap=_one_only(book.findall('.//heading[@toc_num=\"'+chap_num+'\"]')).getparent()\n",
    "    chapLastPara=str(max([int(e.attrib['num']) for e in chap if e.tag=='p' and 'num' in e.attrib]))\n",
    "    toc_chap.attrib['para_last']=chapLastPara\n",
    "    ee0={}\n",
    "    # find first DOM element for each sectioning piece\n",
    "    for toc_sect in toc_chap.iter():\n",
    "        if toc_sect.tag=='chapter': continue\n",
    "        try: para,title,starts_at=toc_sect.attrib['para'],toc_sect.attrib['title'],toc_sect.attrib.get('starts_at',None)\n",
    "        except KeyError:\n",
    "            print(f'Missing keyword? line {toc_sect.sourceline} {toc_sect.tag}')\n",
    "            raise\n",
    "        if len(pp:=list(chap.findall('.//p[@num=\"'+para+'\"]')))!=1:\n",
    "            print(f'{chap_num} {para=} {starts_at=}')\n",
    "        elem0=_one_only(chap.findall('.//p[@num=\"'+para+'\"]'))\n",
    "        if starts_at is not None:\n",
    "            for ix in itertools.count(flatBook.index(elem0)+1):\n",
    "                if ix>=len(flatBook): raise RuntimeError(f'No match for \"{starts_at}\".')\n",
    "                e=flatBook[ix]\n",
    "                if e.tag not in ('span','em'): continue\n",
    "                if not e.text.startswith(starts_at): continue\n",
    "                parent=e.getparent()\n",
    "                if parent.index(e)>0: raise RuntimeError(f'start_at matched on {e.tag} (line {e.sourceline}) but it is not the first child of its parent <{parent.tag}> (line {parent.sourceline}) — not splitting paragraphs.')\n",
    "                if parent.tag=='p': pass\n",
    "                elif parent.tag=='line':\n",
    "                    parent=parent.getparent()\n",
    "                    assert parent.tag=='verse'  \n",
    "                else: raise RuntimeError(f'Matched content trouble: parent of {e.tag} (line {e.sourceline}) must be <p> or <line> (not {parent.tag}).')\n",
    "                elem0=parent\n",
    "                break\n",
    "            # if elem0 is None: raise RuntimeError(f'start_at did not match anything (chapter {chap_num}, line {e.sourceline}, {starts_at=})')\n",
    "        ee0[toc_sect]=elem0\n",
    "        assert elem0.getparent().tag=='struct-2-chapter'\n",
    "    def _subdivide(sects,level,lastPara):\n",
    "        sect=None\n",
    "        for isect,sect in enumerate(sects):\n",
    "            # print(sect.sourceline)\n",
    "            l2=level+3\n",
    "            new=etree.Element(f'struct-{l2}-{level*\"sub\"}section')\n",
    "            new.append(etree.Element(f'heading')) # -{l2}-{level*\"sub\"}section'))\n",
    "            new[-1].text=sect.attrib['title']\n",
    "            new.attrib['par_begin']=sect.attrib['para']\n",
    "            if isect==len(sects)-1:\n",
    "                eAfter=None\n",
    "                new.attrib['par_end']=sect.attrib['para_end']=lastPara\n",
    "            else:\n",
    "                sAfter=sects[isect+1]\n",
    "                eAfter=ee0[sAfter]\n",
    "                new.attrib['par_end']=sect.attrib['para_end']=str(int(sAfter.attrib['para'])-(0 if 'starts_at' in sAfter.attrib else 1))\n",
    "            e=ee0[sect]\n",
    "            e.addprevious(new)\n",
    "            while True:\n",
    "                ee=e.getnext()\n",
    "                new.append(e)\n",
    "                e=ee\n",
    "                if e==eAfter or e is None: break\n",
    "            _subdivide(sect,level=level+1,lastPara=new.attrib['par_end'])\n",
    "        return [sect]\n",
    "    _subdivide(toc_chap,level=0,lastPara=chapLastPara)\n",
    "            \n",
    "\n",
    "# re-apply to the book\n",
    "#open('xml/book.7.xml','w').write(etree.tostring(book,encoding='unicode',pretty_print=True))\n",
    "open('build/book.sectioned.xml','w').write(etree.tostring(book,encoding='unicode',pretty_print=True))\n",
    "open('build/toc.more.xml','w').write(etree.tostring(toc,encoding='unicode',pretty_print=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dca4cd0-dfdd-4529-8587-ae6b6dc227b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git, urllib.parse\n",
    "vismCommit=(head:=git.Repo(search_parent_directories=True).head).object.hexsha[:7]\n",
    "vismCommitTimestampQuery=urllib.parse.quote('in version '+vismCommit+' dated '+head.commit.committed_datetime.date().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a2e7df-ac68-4940-a2d7-caad2e09ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BODY\n",
      "INDEX\n",
      "GLOSSARY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56792"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re\n",
    "##\n",
    "## LaTeX output\n",
    "##\n",
    "book=tree=etree.parse('build/book.sectioned.xml',etree.XMLParser()).getroot() \n",
    "index=tree=etree.parse('src/index.xml',etree.XMLParser()).getroot() \n",
    "gloss=tree=etree.parse('src/gloss.xml',etree.XMLParser()).getroot() \n",
    "\n",
    "editorial_titles=False\n",
    "\n",
    "def _latex_writer(e,lev=0,ord=-1):\n",
    "    def _rep(t): return t.replace('&','\\\\&')\n",
    "    def _recurse(e,lev=lev):\n",
    "        if e.text is not None and len(e)==0: return _rep(e.text)\n",
    "        return ''.join([_latex_writer(e2,lev=lev+1,ord=ord) for ord,e2 in enumerate(e)])\n",
    "    def _nobraces(t):\n",
    "        #if t.strip().endswith(']'):\n",
    "        return t.replace('[','').replace(']','')\n",
    "        #return t\n",
    "    def _title(sect,e):\n",
    "        t=_recurse(e)\n",
    "        if sect in ('chapter','part'):\n",
    "            if 'subtitle_pali' not in e.attrib: return f'\\\\{sect}'+'{'+t+'}'\n",
    "            else: return f'\\\\{sect}[{t}]{{{t}\\\\newline{{\\\\textnormal{{\\emph{{{e.attrib[\"subtitle_pali\"]}}}}}}}}}'\n",
    "        struct=e.getparent()\n",
    "        if 'par_begin' in struct.attrib:\n",
    "            p0,p1=int(struct.attrib['par_begin']),int(struct.attrib['par_end'])\n",
    "            if p0==p1: t2=f'§{p0}'\n",
    "            else: t2=f'§{p0}–{p1}'\n",
    "            # return '\\\\'+sect+'[\\\\protect\\\\numberline{'+t2+'}'+t+']{\\\\ifplastex\\\\else\\\\kern-1em\\\\fi{}'+t+'}'\n",
    "            return '\\\\'+sect+'[\\\\vismAlignedParas{'+t2+'}'+t+']{'+t+'}' #'\\\\ifplastex\\\\else\\\\hfill '+t2+'\\\\fi}'\n",
    "            # return '\\\\def\\\\vismNextParRange{'+t2+'}\\\\'+sect+'{'+t+'}'\n",
    "        else: return '\\\\'+sect+'{'+t+'}'\n",
    "    ret=''\n",
    "    ind=2*lev*'  ' \n",
    "    if isinstance(e,etree._Comment): return ''\n",
    "    if e.tag=='book': return _recurse(e)\n",
    "    elif e.tag=='em':\n",
    "        if len(e)>0: raise RuntimeError(f'<em> with child elements, line {e.sourceline}')\n",
    "        if e.text is None: return ''\n",
    "        return '\\\\emph{'+_rep(e.text)+'}'\n",
    "    elif e.tag=='span':\n",
    "        if len(e)>0: raise RuntimeError(f'<span> with child elements, line {e.sourceline}')\n",
    "        if e.text is None: return ''\n",
    "        tx=_rep(e.text)\n",
    "        if (fam:=e.attrib.get('family',None)) is None: return tx\n",
    "        elif fam=='italic': return '\\\\emph{'+tx+'}'\n",
    "        elif fam=='bold': return '\\\\textbf{'+tx+'}'\n",
    "        elif fam=='smallcaps': return '\\\\textsc{'+tx+'}'\n",
    "        elif fam=='bold-italic': return '\\\\textbf{\\\\emph{'+tx+'}}'\n",
    "        else: raise RuntimeError(f'Unrecognized family {fam}')\n",
    "    elif e.tag=='p':\n",
    "        if not editorial_titles and 'editorial_title' in e.attrib: return ''\n",
    "        ret='\\n\\n'+ind if ord>0 else ''\n",
    "        if 'anchor' in e.attrib:\n",
    "            num,anchor=e.attrib['num'],e.attrib['anchor']\n",
    "            # ret+='\\\\paragraph{§'+num+'.}\\\\vismHypertarget{'+anchor+'}{}\\\\marginnote{\\\\footnotesize\\\\textcolor{purple}{'+anchor+'}}{}\\n'+ind\n",
    "            ret+='\\\\vismParagraph{'+anchor+'}{'+num+'}{}\\n'+ind\n",
    "        return ret+_recurse(e)\n",
    "    elif e.tag=='footnote':\n",
    "        check=r'\\vismAssertFootnoteCounter{'+e.attrib['mark']+'}'\n",
    "        if 'reference_existing_footnote' in e.attrib: return check+r'\\footnotemark[\\value{footnote}]'\n",
    "        elif anchor:=e.attrib.get('anchor',None): return '\\\\footnote{'+check+'\\\\vismHypertarget{'+anchor+'}{}\\\\marginnote{\\\\footnotesize\\\\textcolor{purple}{'+anchor+'}}'+_recurse(e)+'}'\n",
    "        else: return '\\\\footnote{'+check+_recurse(e)+'}'\n",
    "    elif e.tag=='verse':\n",
    "        assert e[-1].tag=='line'\n",
    "        e[-1].attrib['last-line']=\"1\"\n",
    "        return '\\n'+ind+'\\\\begin{verse}\\n'+_recurse(e)+ind+'\\\\end{verse}\\n'\n",
    "    elif e.tag=='line': return ind+_recurse(e)+(r'\\\\{}' if not 'last-line' in e.attrib else '')+'\\n'\n",
    "    elif e.tag.startswith('heading'): return '' # handled in struct-*\n",
    "    elif e.tag.startswith('struct-'):\n",
    "        level,tail=int((m:=re.match('struct-(?P<tail>(?P<level>[0-9]+)-.*)',e.tag)).group('level')),m.group('tail')\n",
    "        heading=e[0]\n",
    "        assert heading.tag.startswith('heading')\n",
    "        toc_num=e.attrib.get('toc_num',None)\n",
    "        if level==1: # part\n",
    "            ret=ind\n",
    "            frontmatter=((name:=e.attrib['name'])=='(Front)')\n",
    "            if frontmatter: ret+='\\\\frontmatter'\n",
    "            elif name=='Part I': ret+='\\\\mainmatter'\n",
    "            if not frontmatter:\n",
    "                ret+='\\n'+ind+_title('part',heading) # no heading for frontmatter\n",
    "                if toc_num: ret+='\\\\label{part-'+toc_num+'}'+ind+'\\\\vismHypertarget{part-'+toc_num+'}\\n'\n",
    "            ret+=_recurse(e)\n",
    "            if name=='Part III': ret+='\\n\\n'+ind+'\\\\appendix'\n",
    "            return ret\n",
    "        elif level==2: # chapter\n",
    "            # \\label is just for PlasTeX which can then name the output file accordingly (the chapter has an $id)\n",
    "            if toc_num: return '\\n'+ind+_title('chapter',heading)+('\\\\label{'+toc_num+'}')+ind+'\\\\vismHypertarget{'+toc_num+'}\\n'\n",
    "            else: return '\\n'+ind+_title('chapter',heading)+_recurse(e)\n",
    "        elif level==3: return '\\n'+ind+_title('section',heading)+_recurse(e)\n",
    "        elif level==4: return '\\n'+ind+_title('subsection',heading)+_recurse(e)\n",
    "        elif level==5: return '\\n'+ind+_title('subsubsection',heading)+_recurse(e)\n",
    "        elif level==6: return '\\n'+ind+r'\\par\\noindent[\\textsc{\\textbf{'+_rep(heading.text)+'}}]'+_recurse(e)\n",
    "        elif level==7: return '\\n'+ind+r'\\par\\noindent[\\emph{\\textbf{'+_rep(heading.text)+'}}]'+_recurse(e)\n",
    "        elif level==8: return '\\n'+ind+r'\\par\\noindent[\\emph{'+_rep(heading.text)+'}]'+_recurse(e)\n",
    "        else: raise RuntimeError(f'Unknown {level=}')\n",
    "    elif e.tag=='printed_page':\n",
    "        #if e.attrib['edition']=='BPS2011': return r'{\\small\\textbf{\\href[page='+e.attrib['page_id']+']{PathofPurification2011.pdf}{\\{'+e.text+' ('+e.attrib['page_id']+')\\}}}}' # marginpar{['+e.text+r']}'\n",
    "        if e.attrib['edition']=='BPS2011':\n",
    "            # return r'\\marginnote[\\footnotesize\\{'+e.text+'('+e.attrib['page_id']+r')\\}]{}[-1ex]' # this is too complicated for PlasTeX\n",
    "            return r'\\marginnote{\\textcolor{teal}{\\footnotesize\\{'+e.text+'('+e.attrib['page_id']+r')\\}}}{}'\n",
    "        elif e.attrib['edition']=='PTS': return r'\\textcolor{brown}{\\textit{['+e.text+']}}'\n",
    "        assert False\n",
    "    elif e.tag=='ref':\n",
    "        if e.attrib['type']=='vism': return r'\\hyperlink{'+e.attrib['target']+r'}{'+e.text+'}{}'\n",
    "        elif e.attrib['type']=='bib': return r'\\textbf{\\cite{'+e.attrib['target']+'}'+(e.attrib['loc'] if 'loc' in e.attrib else '')+'}'\n",
    "        # r'\\fbox{'+e.text+'→'+e.attrib['target']+'}'\n",
    "        assert False\n",
    "    elif e.tag in ('index','glossary'):\n",
    "        title,subtitle=_rep(e.attrib['title']),_rep(e.attrib.get('subtitle',None))\n",
    "        ret='\\\\chapter['+title+']{'+title+'\\\\* {\\large '+subtitle+'}}'\n",
    "        if ii:=e.findall('introductory'):\n",
    "            assert len(ii)==1\n",
    "            ret+=_recurse(ii[0])\n",
    "        ret+=r'\\begin{multicols}{2}\\parskip=.2\\baselineskip\\RaggedRight\\parindent=-1em\\leftskip=1em '+_recurse(e)+r'\\end{multicols}'\n",
    "        return ret\n",
    "    elif e.tag=='introductory': return '' # already handled in index/glossary\n",
    "    elif e.tag=='entry':\n",
    "        return r'\\par\\textbf{'+_rep(e.attrib['title'])+'} '+_recurse(e)+'\\n'\n",
    "    elif e.tag=='raw':\n",
    "        return open('latex/'+e.attrib['file']+'.tex','r').read()\n",
    "    elif e.tag=='TODO':\n",
    "        return r'\\textbf{[TODO: '+e.text+']}'\n",
    "    raise RuntimeError(f'Unhandled tag <{e.tag}>')\n",
    "\n",
    "os.makedirs('build/latex',exist_ok=True)\n",
    "\n",
    "vismCommitTimestampQuery_=vismCommitTimestampQuery.replace(\"%\",\"\\\\%\")\n",
    "open('build/latex/vism-defs.tex','w').write(f'''\n",
    "    \\\\def\\\\vismCommit{{{vismCommit}}}\\n\n",
    "    \\\\def\\\\vismCommitTimestampQuery{{{vismCommitTimestampQuery_}}}\\n\n",
    "''')\n",
    "\n",
    "\n",
    "print('BODY')\n",
    "open('build/latex/vism-body.tex','w').write(''.join(_latex_writer(book)))\n",
    "print('INDEX')\n",
    "open('build/latex/vism-index.tex','w').write(''.join(_latex_writer(index)))\n",
    "print('GLOSSARY')\n",
    "open('build/latex/vism-glossary.tex','w').write(''.join(_latex_writer(gloss)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac448a81-7cd8-4e25-9c06-2ce636009dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ build/sphinx/source/part-1.rst\n",
      "   → build/sphinx/source/ch-01.rst\n",
      "   → build/sphinx/source/ch-02.rst\n",
      "→ build/sphinx/source/part-2.rst\n",
      "   → build/sphinx/source/ch-03.rst\n",
      "   → build/sphinx/source/ch-04.rst\n",
      "→ build/sphinx/source/part-3.rst\n",
      "   → build/sphinx/source/ch-05.rst\n",
      "   → build/sphinx/source/ch-06.rst\n",
      "   → build/sphinx/source/ch-07.rst\n",
      "   → build/sphinx/source/ch-08.rst\n",
      "   → build/sphinx/source/ch-09.rst\n",
      "   → build/sphinx/source/ch-10.rst\n",
      "   → build/sphinx/source/ch-11.rst\n",
      "   → build/sphinx/source/ch-12.rst\n",
      "   → build/sphinx/source/ch-13.rst\n",
      "   → build/sphinx/source/ch-14.rst\n",
      "   → build/sphinx/source/ch-15.rst\n",
      "→ build/sphinx/source/part-4.rst\n",
      "   → build/sphinx/source/ch-16.rst\n",
      "   → build/sphinx/source/ch-17.rst\n",
      "   → build/sphinx/source/ch-18.rst\n",
      "   → build/sphinx/source/ch-19.rst\n",
      "   → build/sphinx/source/ch-20.rst\n",
      "   → build/sphinx/source/ch-21.rst\n",
      "   → build/sphinx/source/ch-22.rst\n",
      "   → build/sphinx/source/ch-23.rst\n",
      "   → build/sphinx/source/ch-24.rst\n",
      "   → build/sphinx/source/ch-25.rst\n",
      "→ build/sphinx/source/index_.rst\n",
      "→ build/sphinx/source/glossary.rst\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "##\n",
    "## Sphinx\n",
    "##\n",
    "book=tree=etree.parse('build/book.sectioned.xml',etree.XMLParser()).getroot() \n",
    "index=tree=etree.parse('src/index.xml',etree.XMLParser()).getroot() \n",
    "gloss=tree=etree.parse('src/gloss.xml',etree.XMLParser()).getroot() \n",
    "\n",
    "\n",
    "class SphinxWriter(object):\n",
    "    def __init__(self,outdir):\n",
    "        self.footnotes={}\n",
    "        self.outdir=outdir\n",
    "        self.chapter=0\n",
    "        self.part=0\n",
    "        self.editorial_titles=False\n",
    "    def _flush(self):\n",
    "        if not self.footnotes: return ''\n",
    "        ret='\\n\\n.. rubric:: Footnotes\\n\\n'\n",
    "        # TODO: multi-paragraph footnotes\n",
    "        for k,vv in self.footnotes.items(): ret+=f'\\n\\n.. _{self.chapter_anchor}.n{k}:\\n\\n.. [#{k}] '+'\\n    '.join([v for v in vv.split('\\n')])+'\\n'\n",
    "        self.footnotes={}\n",
    "        return ret\n",
    "    def _rep(self,t): return t # .replace('&','\\\\&') \n",
    "    def recurse(self,e):\n",
    "        if e.text is not None and len(e)==0: return self._rep(e.text)\n",
    "        return ''.join([self.write(e2,ord=ord) for ord,e2 in enumerate(e)])\n",
    "    def title(self,e,level,anchor=None,prefix=None):\n",
    "        ret=''\n",
    "        if anchor: ret+='\\n\\n.. _'+anchor+':'\n",
    "        t=(e if isinstance(e,str) else self.recurse(e))\n",
    "        if prefix: t=prefix+'. '+t\n",
    "        return ret+'\\n\\n'+t+'\\n'+len(t)*('#*=-^\"\\''[level])\n",
    "    def enclose(self,t,c):\n",
    "        if t.strip()=='': return ' '\n",
    "        ret=t\n",
    "        if ret.endswith(' '): ret=ret.rstrip()+c+' '\n",
    "        else: ret=ret+c+'\\\\ '\n",
    "        if ret.startswith(' '): ret=' '+c+ret.lstrip()\n",
    "        else: ret=c+ret\n",
    "        return ret\n",
    "\n",
    "    def write(self,e,ord=-1):\n",
    "        def _nobraces(t):\n",
    "            #if t.strip().endswith(']'):\n",
    "            return t.replace('[','').replace(']','')\n",
    "            #return t\n",
    "        if isinstance(e,etree._Comment): return''\n",
    "        elif e.tag=='em':\n",
    "            assert len(e)==0\n",
    "            if e.text is None: return ''\n",
    "            return self.enclose(self._rep(e.text),'*')\n",
    "        elif e.tag=='span':\n",
    "            assert len(e)==0\n",
    "            if e.text is None: return ''\n",
    "            tx=self._rep(e.text)\n",
    "            if (fam:=e.attrib.get('family',None)) is None: return tx\n",
    "            elif fam=='italic': return self.enclose(tx,'*')\n",
    "            elif fam=='bold': return self.enclose(tx,'**')\n",
    "            elif fam=='smallcaps': return self.enclose(tx,'``')\n",
    "            elif fam=='bold-italic': return self.enclose(tx,'``')\n",
    "            else: raise RuntimeError(f'Unrecognized family {fam}')\n",
    "        elif e.tag=='p':\n",
    "            if not self.editorial_titles and 'editorial_title' in e.attrib: return ''\n",
    "            if anchor:=e.attrib.get('anchor',None):\n",
    "                # pre=f'\\n\\n.. _{anchor}:\\n\\n**§{e.attrib[\"num\"]}** '\n",
    "                pre=f'\\n\\n.. _{anchor}:\\n\\n`§{e.attrib[\"num\"]} <https://github.com/eudoxos/vism/issues/new?title=issue%20at%20{anchor}&body=({vismCommitTimestampQuery})>`__ '\n",
    "            else: pre=('\\n\\n' if ord>0 else '')\n",
    "            return pre+self.recurse(e)\n",
    "        # elif e.tag=='vism-para': return f'\\n\\n.. _{self.fixanchor(e.attrib[\"anchor\"])}:\\n\\n**§{e.text}** '\n",
    "        elif e.tag=='footnote':\n",
    "            anchor=e.attrib.get(\"anchor\",str(len(self.footnotes)+1))\n",
    "            mark=e.attrib['mark']\n",
    "            if 'reference_existing_footnote' in e.attrib:\n",
    "                return f' [#{mark}]_'\n",
    "            self.footnotes[mark]=self.recurse(e)\n",
    "            return f' [#{mark}]_ '\n",
    "        elif e.tag=='verse':\n",
    "            return '\\n\\n'+self.recurse(e)\n",
    "        elif e.tag=='line': return ('\\n\\n' if ord==0 else '')+'\\n| '+self.recurse(e)+('\\n' if 'last-line' in e.attrib else '')\n",
    "        elif e.tag.startswith('heading'): return '' # handled in struct-*\n",
    "        elif e.tag.startswith('struct-'):\n",
    "            level,tail=int((m:=re.match('struct-(?P<tail>(?P<level>[0-9]+)-.*)',e.tag)).group('level')),m.group('tail')\n",
    "            heading=e[0]\n",
    "            assert heading.tag.startswith('heading')\n",
    "            toc_num=e.attrib.get('toc_num',None)\n",
    "            if level==1: # part\n",
    "                self.part+=1\n",
    "                f=f'{self.outdir}/part-{self.part}.rst'\n",
    "                self.partOut=open(f,'w')\n",
    "                print(f'→ {f}')\n",
    "                if toc_num:\n",
    "                    toc_num='part-'+toc_num\n",
    "                    self.partOut.write(self.title(heading,level=1,anchor=toc_num,prefix=e.attrib[\"toc_name\"])+'\\n\\n.. toctree::\\n   :numbered:\\n   :maxdepth: 6\\n\\n')\n",
    "                for chap in e:\n",
    "                    self.partOut.write('\\n   '+self.write(chap))\n",
    "                self.partOut.close()\n",
    "                return None\n",
    "            elif level==2:\n",
    "                self.chapter+=1\n",
    "                f=f'ch-{self.chapter:02d}.rst'\n",
    "                ff=f'{self.outdir}/{f}'\n",
    "                print(f'   → {ff}')\n",
    "                out=open(ff,'w')\n",
    "                self.chapter_anchor=e.attrib.get('toc_num',None)\n",
    "                ## TODO: e.attrib['subtitle_pali']\n",
    "                out.write(self.title(e,level=2,anchor=e.attrib.get('toc_num',None),prefix=e.attrib.get('toc_num',None)))\n",
    "                out.write(self.recurse(e)+self._flush())\n",
    "                return f\n",
    "            elif 3<=level<=6:\n",
    "                return self.title(e,level=level)\n",
    "            else:\n",
    "                dd={7:'**',8:'*'}[level]\n",
    "                return '\\n\\n'+dd+'['+e.text+']'+dd+'\\ '\n",
    "        elif e.tag=='book':\n",
    "            for e2 in e: self.write(e2)\n",
    "            return None\n",
    "        # elif e.tag=='footref': return f'[#{e.text}]_'\n",
    "        elif e.tag=='printed_page':\n",
    "            #if e.attrib['edition']=='BPS2011': return r'{\\small\\textbf{\\href[page='+e.attrib['page_id']+']{PathofPurification2011.pdf}{\\{'+e.text+' ('+e.attrib['page_id']+')\\}}}}' # marginpar{['+e.text+r']}'\n",
    "            if e.attrib['edition']=='BPS2011': return f'*[{e.text}/{e.attrib[\"page_id\"]}]* '\n",
    "            elif e.attrib['edition']=='PTS': return f' ``{e.text}`` '\n",
    "            assert False\n",
    "        elif e.tag=='ref':\n",
    "            if e.attrib['type']=='vism':\n",
    "                return f':ref:`{e.text} <{e.attrib[\"target\"]}>`'\n",
    "            elif e.attrib['type']=='bib': return f' [{e.attrib[\"target\"]}]_ '+(self.enclose(e.attrib[\"loc\"],'*') if 'loc' in e.attrib else '')+' '\n",
    "            assert False\n",
    "        elif e.tag in ('index','glossary'):\n",
    "            title,subtitle=e.attrib['title'],e.attrib['subtitle']\n",
    "            if e.tag=='index':      out,ret='index_',self.title(e=f'{title} ({subtitle})',level=1,anchor='index')\n",
    "            elif e.tag=='glossary': out,ret='glossary',self.title(e=f'{title} ({subtitle})',level=1,anchor='glossary')\n",
    "            if ii:=e.findall('introductory'):\n",
    "                assert len(ii)==1\n",
    "                ret+='\\n\\n'+self.recurse(ii[0])\n",
    "            ret+='\\n\\n.. glossary::'\n",
    "            ret+=self.recurse(e)\n",
    "            f=f'{self.outdir}/{out}.rst'\n",
    "            print(f'→ {f}')\n",
    "            open(f,'w').write(ret)\n",
    "            return\n",
    "        elif e.tag=='introductory': return ''\n",
    "        elif e.tag=='entry':\n",
    "            title=e.attrib[\"title\"].replace(\"*\",\"\\\\*\")\n",
    "            return f'\\n\\n   {title}\\n          '+self.recurse(e) # {e.attrib[\"desc\"]}'\n",
    "        elif e.tag=='raw':\n",
    "            return '\\n\\n'+open('sphinx/'+e.attrib['file']+'.rst','r').read()+'\\n\\n'\n",
    "        elif e.tag=='TODO':\n",
    "            return f'**TODO: {e.text}**\\ '\n",
    "        raise RuntimeError(f'Unhandled tag <{e.tag}>')\n",
    "os.makedirs('build/sphinx/source',exist_ok=True)\n",
    "writer=SphinxWriter(outdir='build/sphinx/source')\n",
    "writer.write(book)\n",
    "writer.write(index)\n",
    "writer.write(gloss)\n",
    "# ''.join(_latex_writer(e) for e in book))\n",
    "#open('/tmp/vism-index.tex','w').write(''.join(_latex_writer(index,list='index')))\n",
    "#open('/tmp/vism-glossary.tex','w').write(''.join(_latex_writer(gloss,list='glossary')))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f884e737-0e3a-448c-88ec-7350b383e612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ build/docbook/vism.xslTNG.xml build/docbook/vism.xslTNG.pretty.xml\n",
      "→ build/docbook/vism.xml build/docbook/vism.pretty.xml\n"
     ]
    }
   ],
   "source": [
    "## DocBook\n",
    "from lxml import etree\n",
    "import os\n",
    "\n",
    "book=etree.parse('build/book.sectioned.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "index=etree.parse('src/index.xml',etree.XMLParser(remove_blank_text=True)).getroot() \n",
    "gloss=etree.parse('src/gloss.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "bookMetadata=etree.parse('docbook/metadata.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "book.append(index)\n",
    "book.append(gloss)\n",
    "bibDocbook=etree.parse('docbook/bib.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "\n",
    "frontmatter=False\n",
    "\n",
    "def _docb_writer(e,ord=0,parent=None,xslTNG=False):\n",
    "    xlinkNs='http://www.w3.org/1999/xlink'\n",
    "    xmlNs='http://www.w3.org/XML/1998/namespace'\n",
    "    xmlPrefix='{'+xmlNs+'}'\n",
    "    editorial_titles=False\n",
    "    \n",
    "    if xslTNG:\n",
    "        xlinkPrefix='{'+xlinkNs+'}'\n",
    "        nsmap={None:'http://docbook.org/ns/docbook','xlink':xlinkNs,'xml':xmlNs}\n",
    "    else:\n",
    "        #nsmap={None:'http://docbook.org/ns/docbook','xml':xmlNs}\n",
    "        #xlinkPrefix=''\n",
    "        nsmap,xlinkPrefix=None,''\n",
    "\n",
    "    def _E(e,text=None,*,subs=[],xml_id=None,**kw):\n",
    "        assert text is None or isinstance(text,str)\n",
    "        ret=etree.Element(e,**kw,nsmap=nsmap) # ,'pub':pubNs})\n",
    "        if xml_id is not None:\n",
    "            # if xslTNG:\n",
    "            ret.attrib[xlinkPrefix+'label']=xml_id\n",
    "            ret.attrib[xmlPrefix+'id']=xml_id\n",
    "        if 'linkend' in kw:\n",
    "            if xslTNG:\n",
    "                ret.attrib[xlinkPrefix+'to']=kw['linkend']\n",
    "                kw.pop('linkend')\n",
    "            pass\n",
    "        ret.text=text\n",
    "        for sub in subs:\n",
    "            if sub is None: continue\n",
    "            if sub.tag=='__FLATTEN__':\n",
    "                for su in sub: ret.append(su)\n",
    "            else: ret.append(sub)\n",
    "        return ret\n",
    "\n",
    "    def _curr_chapter(e):\n",
    "        while (e:=e.getparent()) is not None:\n",
    "            if e.tag=='struct-2-chapter':\n",
    "                heading=e[0]\n",
    "                assert heading.tag.startswith('heading')\n",
    "                return heading.attrib.get('toc_num',None)\n",
    "\n",
    "\n",
    "    def _recurse(e,dbg=False):\n",
    "        if e.text is not None and len(e)==0:\n",
    "            if dbg: print('=',e.text)\n",
    "            return [_E('phrase',e.text)]\n",
    "        if e.text is not None and e.text!='' and len(e)>0:\n",
    "            print('$$$$',e.tag,e.sourceline) # ,len(e.text),e.text)\n",
    "        ret=[_docb_writer(e2,ord=ord,parent=e) for ord,e2 in enumerate(e)]\n",
    "        if dbg: print('|'.join([r.text for r in ret if r.text]))\n",
    "        return ret\n",
    "    if isinstance(e,etree._Comment): return None\n",
    "    if e.tag=='book':\n",
    "        # return _E('book',xmlns='http://docbook.org/ns/docbook',version=\"5.0\",subs=_recurse(e))\n",
    "        b=_E('book',version=\"5.2\",subs=[bookMetadata]+_recurse(e))\n",
    "        b.append(bibDocbook)\n",
    "        return b\n",
    "        # b.attrib['xmlns:pub']=\"http://docbook.org/ns/docbook/publishers\"\n",
    "    if e.tag=='em':\n",
    "        assert len(e)==0\n",
    "        return _E('emphasis',e.text)  \n",
    "    elif e.tag=='span':\n",
    "        assert len(e)==0\n",
    "        if e.text is None: return None\n",
    "        if (fam:=e.attrib.get('family',None)) is None: return _E('phrase',e.text)\n",
    "        elif fam=='italic': return _E('emphasis',e.text)\n",
    "        elif fam=='bold': return _E('emphasis',e.text,role='bold')\n",
    "        elif fam=='smallcaps': return _E('emphasis',e.text,role='smallcaps')\n",
    "        elif fam=='bold-italic': return _E('emphasis',e.text,role='bold-italic')\n",
    "        else: raise RuntimeError(f'Unrecognized family {fam}')\n",
    "    elif e.tag=='p':\n",
    "        if not editorial_titles and 'editorial_title' in e.attrib: return None\n",
    "        if 'anchor' in e.attrib:\n",
    "            return _E('formalpara',xml_id=e.attrib['anchor'],subs=[_E('title','§'+e.attrib['num']),_E('para',subs=_recurse(e))])\n",
    "        else: return _E('para',subs=_recurse(e))\n",
    "    elif e.tag=='footnote':\n",
    "        if (ch:=_curr_chapter(e)) is None:\n",
    "            assert 'reference_existing_footnote' not in e.attrib\n",
    "            return _E('footnote',subs=_recurse(e))\n",
    "        else:\n",
    "            label=f'{ch}.n{e.attrib[\"mark\"]}'\n",
    "            if 'reference_existing_footnote' in e.attrib: return _E('footnoteref',linkend=label)\n",
    "            return _E('footnote',subs=_recurse(e),xml_id=label)\n",
    "    elif e.tag=='verse':\n",
    "        for ich,ch in enumerate(e):\n",
    "            if not ch.tag=='line':\n",
    "                raise RuntimeError(f'<verse> may contain only <line> elements (<verse> at line {e.sourceline}; child #{ich} <{ch.tag}>, line {ch.sourceline})')\n",
    "        return _E('linegroup',subs=[_E('speaker')]+_recurse(e))\n",
    "        return _E('linegroup',subs=[_E('speaker')]+_recurse(e))\n",
    "        # return _E('poetry',subs=[_E('linegroup',subs=_recurse(e))])\n",
    "    elif e.tag=='line': return _E('line',subs=_recurse(e))\n",
    "    elif e.tag.startswith('struct-'):\n",
    "        level,tail=int((m:=re.match('struct-(?P<tail>(?P<level>[0-9]+)-.*)',e.tag)).group('level')),m.group('tail')\n",
    "        heading=e[0]\n",
    "        assert heading.tag.startswith('heading')\n",
    "        toc_num=e.attrib.get('toc_num',None)\n",
    "        title=[_E('title',subs=_recurse(heading))]\n",
    "        if level==1: # part\n",
    "            global frontmatter\n",
    "            frontmatter=((name:=e.attrib['name'])=='(Front)')\n",
    "            if frontmatter: return _E('__FLATTEN__',subs=_recurse(e))\n",
    "            kw=({'xml_id':'part-'+toc_num} if toc_num else {})\n",
    "            return _E('part',subs=title+_recurse(e),**kw)\n",
    "        elif level==2:\n",
    "            if frontmatter: return _E('preface',subs=title+_recurse(e))\n",
    "            if sub:=heading.get('subtitle_pali',None): title+=[_E('subtitle',subs=[_E('phrase',subs=[_E('emphasis',text=sub)])])]\n",
    "            return _E('chapter',subs=title+_recurse(e),xml_id=toc_num)\n",
    "        else: return _E('section',subs=title+_recurse(e))\n",
    "    elif e.tag.startswith('heading'): return None\n",
    "    # elif e.tag in ('struct-3-section','struct-4-subsection','struct-5-subsubsection','struct-6-subsubsubsection','struct-7-subsubsubsubsection','struct-8-subsubsubsubsubsection'): return _E('section',subs=_recurse(e))\n",
    "    elif e.tag=='printed_page':\n",
    "        # return None # XXXXX\n",
    "        if e.attrib['edition']=='BPS2011': return _E('literal',f'[{e.text}|{e.attrib[\"page_id\"]}]')\n",
    "        elif e.attrib['edition']=='PTS': return _E('varname',f'({e.text})')\n",
    "    elif e.tag=='ref':\n",
    "        if e.attrib['type']=='vism': return _E('link',e.text,linkend=e.attrib['target'])\n",
    "        elif e.attrib['type']=='bib':\n",
    "            if 'loc' in e.attrib: return _E('phrase',subs=[_E('citation',e.attrib['target']),_E('phrase',e.attrib['loc'])])\n",
    "            return _E('citation',e.attrib['target'])\n",
    "        assert False\n",
    "    elif e.tag=='index': return _E('index',subs=[_E('title',e.attrib['title']),_E('subtitle',e.attrib['subtitle'])]+_recurse(e))\n",
    "    elif e.tag=='glossary':  return _E('glossary',subs=[_E('title',e.attrib['title']),_E('subtitle',e.attrib['subtitle'])]+_recurse(e))\n",
    "    elif e.tag=='introductory': return _E('para',subs=_recurse(e))\n",
    "    elif e.tag=='entry':\n",
    "        if parent.tag=='index': return _E('primaryie',subs=[_E('emphasis',text=e.attrib['title'],role='bold')]+_recurse(e))\n",
    "        elif parent.tag=='glossary': return _E('glossentry',subs=[_E('glossterm',text=e.attrib['title'])]+[_E('glossdef',subs=_recurse(e))])\n",
    "        print(parent.tag)\n",
    "        assert False\n",
    "    elif e.tag=='raw':\n",
    "        return etree.parse('docbook/'+e.attrib['file']+'.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "    elif e.tag=='TODO':\n",
    "        return _E('emphasis','[TODO: '+e.text+']',role='bold')\n",
    "    raise RuntimeError(f'Unhandled tag <{e.tag}>')\n",
    "\n",
    "def _fix_formalpara(book):\n",
    "    for fp in book.findall('.//formalpara'):\n",
    "        subs=[]\n",
    "        p=fp\n",
    "        while ((p:=p.getnext()) is not None) and (p.tag in ('para','linegroup')):\n",
    "            subs.append(p)\n",
    "        for p in subs: fp.append(p)\n",
    "    return book\n",
    "            \n",
    "for xslTNG in True,False:\n",
    "    docb=_docb_writer(book,xslTNG=xslTNG)\n",
    "    docb=_fix_formalpara(docb)\n",
    "    kw=dict(doctype=None,xml_declaration=True,encoding='utf-8')\n",
    "    os.makedirs('build/docbook',exist_ok=True)\n",
    "    stem='vism.xslTNG' if xslTNG else 'vism'\n",
    "    open(f'build/docbook/{stem}.xml','wb').write(etree.tostring(docb,pretty_print=False,**kw))\n",
    "    open(f'build/docbook/{stem}.pretty.xml','wb').write(etree.tostring(docb,pretty_print=True,**kw))\n",
    "    print(f'→ build/docbook/{stem}.xml build/docbook/{stem}.pretty.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "427faf38-5d88-4eb2-ab58-704d56266524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw ignored\n",
      "Raw ignored\n",
      "Raw ignored\n",
      "Raw ignored\n",
      "Raw ignored\n",
      "→ build/html5/vism.html5 build/html5/vism.pretty.html5\n"
     ]
    }
   ],
   "source": [
    "## HTML5\n",
    "from lxml import etree\n",
    "import os\n",
    "import re\n",
    "\n",
    "book=etree.parse('build/book.sectioned.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "index=etree.parse('src/index.xml',etree.XMLParser(remove_blank_text=True)).getroot() \n",
    "gloss=etree.parse('src/gloss.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "# TODO: bibliography\n",
    "\n",
    "frontmatter=False\n",
    "\n",
    "def _html5_writer(e,ord=0,parent=None):\n",
    "    editorial_titles=False\n",
    "    \n",
    "    def _E(e,text=None,*,subs=[],xml_id=None,**kw):\n",
    "        assert text is None or isinstance(text,str)\n",
    "        if 'class_' in kw: kw['class']=kw.pop('class_')\n",
    "        ret=etree.Element(e,**kw) #,nsmap=nsmap) # ,'pub':pubNs})\n",
    "        if xml_id is not None: ret.attrib['id']=xml_id\n",
    "        ret.text=text\n",
    "        assert not isinstance(subs,etree._Element)\n",
    "        assert isinstance(subs,list)\n",
    "        for sub in subs:\n",
    "            if sub is None: continue\n",
    "            if sub.tag=='__FLATTEN__':\n",
    "                for su in sub: ret.append(su)\n",
    "            else: ret.append(sub)\n",
    "        return ret\n",
    "\n",
    "    def _curr_chapter(e):\n",
    "        while (e:=e.getparent()) is not None:\n",
    "            if e.tag=='struct-2-chapter':\n",
    "                assert e[0].tag.startswith('heading')\n",
    "                return e[0].get('toc_num',None)\n",
    "\n",
    "    def _recurse(e,dbg=False):\n",
    "        if e.text is not None and len(e)==0:\n",
    "            if dbg: print('=',e.text)\n",
    "            return [_E('span',e.text)]\n",
    "        if e.text is not None and e.text!='' and len(e)>0:\n",
    "            print('$$$$',e.tag,e.sourceline) # ,len(e.text),e.text)\n",
    "            assert False\n",
    "        ret=[_html5_writer(e2,ord=ord,parent=e) for ord,e2 in enumerate(e)]\n",
    "        if dbg: print('|'.join([r.text for r in ret if r.text]))\n",
    "        return ret\n",
    "    if isinstance(e,etree._Comment): return None\n",
    "    if e.tag=='book':\n",
    "        # _E('head',subs=[_E('link',rel='stylesheet',href='style.A4.css')]),\n",
    "        return _E('html',subs=[_E('body',subs=_recurse(e))],lang='en')\n",
    "    if e.tag=='em':\n",
    "        assert len(e)==0\n",
    "        return _E('em',e.text)  \n",
    "    elif e.tag=='span':\n",
    "        assert len(e)==0\n",
    "        if e.text is None: return None\n",
    "        if (fam:=e.attrib.get('family',None)) is None: return _E('span',e.text)\n",
    "        elif fam=='italic': return _E('em',e.text)\n",
    "        elif fam=='bold': return _E('strong',e.text)\n",
    "        elif fam=='smallcaps': return _E('span',e.text,style='font-variant: small-caps;')\n",
    "        elif fam=='bold-italic': return _E('strong',e.text)\n",
    "        else: raise RuntimeError(f'Unrecognized family {fam}')\n",
    "    elif e.tag=='p':\n",
    "        if not editorial_titles and 'editorial_title' in e.attrib: return None\n",
    "        if anchor:=e.get('anchor',None):\n",
    "            kw=dict(id=anchor,class_='vism-para')\n",
    "            pre=[_E('strong','§'+e.attrib['num']+'. ')]\n",
    "        else: kw,pre={},[]\n",
    "        return _E('p',subs=pre+_recurse(e),**kw)\n",
    "    elif e.tag=='footnote':\n",
    "        if (ch:=_curr_chapter(e)) is None:\n",
    "            assert 'reference_existing_footnote' not in e.attrib\n",
    "            return _E('span',subs=_recurse(e),class_='footnote')\n",
    "        else:\n",
    "            label=f'{ch}.n{e.attrib[\"mark\"]}'\n",
    "            if 'reference_existing_footnote' in e.attrib:\n",
    "                return _E('span',f'FIXME: see the other footnote {label}.',class_='footnote')\n",
    "            return _E('span',subs=_recurse(e),id=label,class_='footnote')\n",
    "    elif e.tag=='verse':\n",
    "        for ich,ch in enumerate(e):\n",
    "            if not ch.tag=='line':\n",
    "                raise RuntimeError(f'<verse> may contain only <line> elements (<verse> at line {e.sourceline}; child #{ich} <{ch.tag}>, line {ch.sourceline})')\n",
    "        return _E('div',subs=_recurse(e),class_='vism-verse')\n",
    "        # return _E('poetry',subs=[_E('linegroup',subs=_recurse(e))])\n",
    "    elif e.tag=='line': return _E('div',subs=_recurse(e))\n",
    "    elif e.tag.startswith('struct-'):\n",
    "        level,tail=int((m:=re.match('struct-(?P<tail>(?P<level>[0-9]+)-.*)',e.tag)).group('level')),m.group('tail')\n",
    "        heading=e[0]\n",
    "        assert heading.tag.startswith('heading')\n",
    "        toc_num=heading.attrib.get('toc_num',None)\n",
    "        title=[_E('h1',subs=_recurse(heading))]\n",
    "        if level==1: # part\n",
    "            global frontmatter\n",
    "            frontmatter=((name:=e.attrib['name'])=='(Front)')\n",
    "            if frontmatter: return _E('__FLATTEN__',subs=_recurse(e))\n",
    "            kw=({'xml_id':'part-'+toc_num} if toc_num else {})\n",
    "            return _E('section',subs=title+_recurse(e),class_='sect-dp1',**kw)\n",
    "        elif level==2:\n",
    "            if frontmatter: return _E('section',subs=title+_recurse(e),class_='sect-dp2')\n",
    "            if sub:=heading.get('subtitle_pali',None): title+=[_E('div',role='doc-subtitle',subs=[_E('span',subs=[_E('emphasis',text=sub)])])]\n",
    "            return _E('section',subs=title+_recurse(e),xml_id=toc_num,class_='sect-dp2')\n",
    "        else: return _E('section',subs=title+_recurse(e),class_=f'sect-dp{level}')\n",
    "    elif e.tag.startswith('heading'): return None\n",
    "    elif e.tag=='printed_page':\n",
    "        if e.attrib['edition']=='BPS2011': return _E('span',f'[{e.text}|{e.attrib[\"page_id\"]}]',class_='vism-page-bps')\n",
    "        elif e.attrib['edition']=='PTS': return _E('span',f'({e.text})',class_='vism-page-pts')\n",
    "    elif e.tag=='ref':\n",
    "        if e.attrib['type']=='vism': return _E('a',e.text,href='#'+e.attrib['target'])\n",
    "        elif e.attrib['type']=='bib':\n",
    "            if 'loc' in e.attrib: return _E('span',subs=[_E('citation',e.attrib['target']),_E('span',e.attrib['loc'])])\n",
    "            return _E('citation',e.attrib['target'])\n",
    "        assert False\n",
    "    elif e.tag in ('index','glossary'):\n",
    "        return _E('section',class_='sect-dp2',subs=[_E('h1',e.attrib['title']),_E('h2',e.attrib['subtitle']),_E('dl',class_='cols-2',subs=_recurse(e))])\n",
    "    #elif e.tag=='glossary':  return _E('section',subs=[_E('title',e.attrib['title']),_E('subtitle',e.attrib['subtitle'])]+_recurse(e))\n",
    "    elif e.tag=='introductory': return _E('p',subs=_recurse(e))\n",
    "    elif e.tag=='entry':\n",
    "        return _E('__FLATTEN__',subs=[_E('dt',text=e.attrib['title']),_E('dd',subs=_recurse(e))])\n",
    "    elif e.tag=='raw':\n",
    "        print('Raw ignored')\n",
    "        return None\n",
    "        # return etree.parse('docbook/'+e.attrib['file']+'.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "    elif e.tag=='TODO':\n",
    "        return _E('strong','[TODO: '+e.text+']',class_='vism-todo')\n",
    "    raise RuntimeError(f'Unhandled tag <{e.tag}>')\n",
    "\n",
    "\n",
    "if 1:\n",
    "    book.append(index)\n",
    "    book.append(gloss)\n",
    "    ht=_html5_writer(book)\n",
    "    os.makedirs('build/html5',exist_ok=True)\n",
    "    open(f'build/html5/{stem}.book.xml','wb').write(etree.tostring(book,pretty_print=True))\n",
    "    kw=dict(doctype=None,xml_declaration=True,encoding='utf-8')\n",
    "    os.makedirs('build/html5',exist_ok=True)\n",
    "    stem='vism'\n",
    "    open(f'build/html5/{stem}.html5','wb').write(etree.tostring(ht,pretty_print=False,**kw))\n",
    "    open(f'build/html5/{stem}.pretty.html5','wb').write(etree.tostring(ht,pretty_print=True,**kw))\n",
    "    print(f'→ build/html5/{stem}.html5 build/html5/{stem}.pretty.html5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60069564-6da5-43bc-ba4b-5baa10c75403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lxml.etree._Element"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=etree.Element('bbb')\n",
    "type(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e56c0-8bda-4e44-bf50-7578f5a577ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "etree.Element"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
