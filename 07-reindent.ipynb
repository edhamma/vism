{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d050232-cd2d-4bc8-ba66-68611e979cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3605280"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "book=etree.parse('src/book.6.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "# re-indentation: no need to do anything\n",
    "if 0:\n",
    "    # verse at the beginning of the paragraph, first line as running text\n",
    "    beginVerse=['IV.66','XVII.161','XVII.210','XVII.212','XVII.218','XVII.230','XVII.237','V.27',]\n",
    "    for a in beginVerse:\n",
    "        pp=book.findall('.//p[@anchor=\"'+a+'\"]')\n",
    "        assert len(pp)==1\n",
    "        p=pp[0]\n",
    "        print(len(p),p[0].tag)\n",
    "        assert (len(p)==1 and p[0].tag=='span') or (len(p)==2 and p[0].tag=='printed_page' and p[1].tag=='span')\n",
    "        v=p.getnext()\n",
    "        assert v.tag=='verse'\n",
    "        for _ in reversed(p): v.insert(0,_)\n",
    "        v.attrib['y']=p.attrib['y']\n",
    "        \n",
    "if 0:\n",
    "    # last line of paragraph broken off\n",
    "    endParaFragment=['II.38','II.42','II.55','II.70','II.74','III.73','III.122','III.127',\n",
    "                     'IV.87',\n",
    "                     'XVII.232','XVII.238','XVII.248','XVII.260','XVII.272','XVII.281',\n",
    "                     'XVII.291','XVIII.7','XX.29','XX.42']\n",
    "    for anchor in endParaFragment:\n",
    "        pp=book.findall('.//p[@anchor=\"'+anchor+'\"]')\n",
    "        assert len(pp)==1\n",
    "        para=pp[0]\n",
    "        # print(anchor,para,para.sourceline)\n",
    "        paraAfter=para.getnext()\n",
    "        while not 'anchor' in paraAfter.attrib: paraAfter=paraAfter.getnext()\n",
    "        para1=paraAfter.getprevious()\n",
    "        para0=para1.getprevious()\n",
    "        #print(paraAfter.attrib['anchor'])\n",
    "        #print(paraLast[-1].tag)\n",
    "        print(anchor,len(para1),[e.tag for e in para1])\n",
    "        print('  ',para0[-1].text)\n",
    "        print('  ',para1[0].text)\n",
    "        assert(para0[-1].tag==para1[0].tag)\n",
    "        para0[-1].text+=' '+para1[0].text\n",
    "        para1.remove(para1[0])\n",
    "        for e in para1: para0.append(e)\n",
    "        # print('   ',len(para0),[e.tag for e in para0])\n",
    "        # print(f'{para[-1].tag=}')\n",
    "\n",
    "if 0:\n",
    "    for p in book.findall('.//p'):\n",
    "        if len(p)>1 or len(p)==0: continue\n",
    "        e0=p[0]\n",
    "        if e0.tag not in ['em','span']: continue\n",
    "        assert e0.text is not None\n",
    "        if len(e0.text)>100: continue\n",
    "        #print(e0.text)\n",
    "        if e0.text.startswith('[') and e0.text.endswith(']') and e0.text[-2]!=':': print(e0.text)\n",
    "        elif 'family' in e0.attrib: print(e0.attrib['family'],e0.text)\n",
    "        \n",
    "\n",
    "if 0:        \n",
    "    for p in book.findall('.//p'):\n",
    "        if len(p)!=1: continue\n",
    "        if p[0].tag!='em': continue\n",
    "        if not (p[0].text.startswith('[') and p[0].text.endswith(']')): continue\n",
    "        if 'title' not in p.attrib: p.attrib['title']='1'\n",
    "if 1:\n",
    "    for p in book.findall('.//p[@title]'):\n",
    "        del p.attrib['title']\n",
    "        p.attrib['editorial_title']=\"1\"\n",
    "        # print(p.attrib['title'])\n",
    "if 1:\n",
    "    def _E(tag,text=None,**kw):\n",
    "        ret=etree.Element(tag,**kw)\n",
    "        ret.text=text\n",
    "        return ret\n",
    "        \n",
    "    import re\n",
    "    for span in book.findall('.//span'):\n",
    "        if (pp:=span.getparent().getparent()).tag=='footnote': continue\n",
    "        if '§' not in span.text: continue\n",
    "        ch=span.getparent()\n",
    "        while ch.tag!='struct-2-chapter':  ch=ch.getparent()\n",
    "        chap=ch.find('.//heading-2-chapter').get('toc_num',None)\n",
    "        noMatch=True\n",
    "        while m:=re.search('(\\[|\\(|—|, )(|cf. |see |See )(?P<para>§(?P<num>[0-9]+)(|f.|ff.))(\\]|\\)|;|,| below| above| and)',span.text):\n",
    "            noMatch=False\n",
    "            span.addprevious(_E('span',text=span.text[:m.start('para')]))\n",
    "            span.addprevious(_E('ref',text=m.group('para'),type=\"vism\",target=f'{chap}.{m.group(\"num\")}'))\n",
    "            print(chap,span.sourceline,m.group('para'))  \n",
    "            span.text=span.text[m.end('para'):]\n",
    "        if noMatch:\n",
    "            while m:=re.search('(?P<head>§§|§)(?P<p1>[0-9]+)(?P<delim>–|,)(?P<p2>[0-9]+)\\)',span.text):\n",
    "                noMatch=False\n",
    "                print(chap,m.group('head'),m.group('p1'),m.group('delim'),m.group('p2'))\n",
    "                span.addprevious(_E('span',text=span.text[:m.start('head')]))\n",
    "                span.addprevious(_E('ref',text=m.group('head')+m.group('p1'),type=\"vism\",target=f'{chap}.{m.group(\"p1\")}'))\n",
    "                span.addprevious(_E('span',text=m.group('delim')))\n",
    "                span.addprevious(_E('ref',text=m.group('p2'),type=\"vism\",target=f'{chap}.{m.group(\"p2\")}'))\n",
    "                span.text=span.text[m.end('p2'):]\n",
    "        if noMatch:\n",
    "            print(span.sourceline,span.text)\n",
    "                            \n",
    "            # print(m)\n",
    "            \n",
    "        # if not m: print(span.text)\n",
    "            \n",
    "            # print(m)\n",
    "            #ix=span.text.index('§')\n",
    "            #print(span.text[max(0,ix-20):ix+20],pp.tag)\n",
    "        \n",
    "\n",
    "open('src/book.6a.xml','w').write(etree.tostring(book,encoding='unicode',pretty_print=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8f650e0-9677-4aa9-97fa-6b3ba95be4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Abhaya Thera , Tipiṭaka Cūḷa \n",
      "47 Abhaya Thera , Dīghabhāṇaka \n",
      "54 Abhaya Thera , Pīṭha \n",
      "656 Anāthapiṇḍika , Cūḷa \n",
      "2340 Chaddanta , Lake \n",
      "2462 Citta , householder \n",
      "4056 Datta Thera , Mahā \n",
      "4786 Dhammarakkhita Thera , Mahā \n",
      "7123 Godatta Thera , Abhidhammika \n",
      "7375 Gutta Thera , Mahā Rohaṇa \n",
      "7387 Haṃsapātana , Lake \n",
      "8903 Kaccāna Thera , Mahā \n",
      "9118 Kaṇṇamuṇḍaka , Lake \n",
      "9126 Kappina Thera , Mahā \n",
      "9130 Karañjiya-vihāra , Mahā \n",
      "9379 Kuṇāla , Lake \n",
      "10610 Mitta Thera , Mahā \n",
      "10633 Moggallāna Thera , Mahā \n",
      "10835 Nāga Thera , Tipiṭaka Cūḷa \n",
      "12136 Panthaka Thera , Cūḷa \n",
      "13199 Rathakāra , Lake \n",
      "13801 Revata Thera , Majjhimabhāṇaka \n",
      "14032 Rohaṇa-Gutta Thera , Mahā \n",
      "14835 Sīhapapāta , Lake \n",
      "14843 Sineru , Mount \n",
      "14887 Siva Thera , Cūḷa \n",
      "15295 Subhaddā , Cūḷa \n",
      "15924 Tissa Thera , Cūḷa-piṇḍapātika \n",
      "15931 Tissa Thera , Koṭapabbatavāsin \n",
      "15948 Tissa Thera , Mahā, Mahā-Karañjiya-vihāra-vāsin \n",
      "15953 Tissa Thera , Padhāniya, Nāgapabbatavāsin \n",
      "15958 Tissa Thera , Piṇḍapātika, Devaputtaraṭṭhavāsin \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "557985"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "ix=etree.parse('src/index.xml',etree.XMLParser(remove_blank_text=True)).getroot()\n",
    "\n",
    "if 0:\n",
    "\n",
    "    def splitEntry(entry,splitter):\n",
    "        assert splitter.tag=='Xspan'\n",
    "        ixs=entry.index(splitter)\n",
    "        ent2=etree.Element('entry',page_id=entry.attrib['page_id'],title=splitter.text.strip())\n",
    "        ent2[:]=entry[ixs+1:]\n",
    "        entry.remove(splitter)\n",
    "        entry.addnext(ent2)\n",
    "        return ent2\n",
    "\n",
    "    for e in ix.findall('.//Xspan'):\n",
    "        assert (ent:=e.getparent()).tag=='entry'\n",
    "        if e.text.endswith('('):\n",
    "            assert (n:=e.getnext()).tag=='em'\n",
    "            assert (nn:=e.getnext().getnext()).tag=='span'\n",
    "            e.text=e.text[:-1]\n",
    "            ent2=splitEntry(ent,e)\n",
    "            ent2.insert(0,sp:=etree.Element('span'))\n",
    "            sp.text='('\n",
    "        else:\n",
    "            assert (n:=e.getnext()).tag=='ref'\n",
    "            splitEntry(ent,e)\n",
    "\n",
    "        \n",
    "for ent in ix.findall('.//entry'):\n",
    "    if len(ent)==0: print(ent.sourceline)\n",
    "    if len(ent)==1: continue\n",
    "    span=ent[0]\n",
    "    ref=ent[1]\n",
    "    if span.tag!='span' or ref.tag!='ref': continue\n",
    "    tx=span.text\n",
    "    if tx.startswith(','):\n",
    "        print(ent.sourceline,ent.attrib['title'],span.text)\n",
    "        ent.attrib['title']+=tx.rstrip()\n",
    "        ent.remove(span)\n",
    "        #span.text='('\n",
    "        # print(span.text)\n",
    "    \n",
    "    # assert e.tag=='entry'\n",
    "    # print(e)\n",
    "    \n",
    "\n",
    "open('src/index.2.xml','w').write(etree.tostring(ix,encoding='unicode',pretty_print=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345df93-deaa-4317-9078-85ca3df47891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
